{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db93b28-a2b8-4fed-8361-cd7944df173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  (\n",
    "    AutoConfig, logging, AutoModel,AutoModelForSequenceClassification, TrainingArguments, AutoTokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6bf5115-1246-446c-ac7e-7fa767c07868",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "47e49dc3-bcd3-4e44-9980-f7e9fa31ed28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/HUPD/hupd-t5-small/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpmen8o02_\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4d23941a884bc0ba70384c61b03cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.93k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/HUPD/hupd-t5-small/resolve/main/tokenizer_config.json in cache at /root/.cache/huggingface/transformers/4413da3c3cd550e44ab2415f5eb2920e7b6c7f677d703241abcdfa4a5347c481.da4b0a812e9b55b173e4c1a2b57215ddfe312d4ae6e6b1696f4be152dab93bef\n",
      "creating metadata file for /root/.cache/huggingface/transformers/4413da3c3cd550e44ab2415f5eb2920e7b6c7f677d703241abcdfa4a5347c481.da4b0a812e9b55b173e4c1a2b57215ddfe312d4ae6e6b1696f4be152dab93bef\n",
      "https://huggingface.co/HUPD/hupd-t5-small/resolve/main/spiece.model not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp7tx8r763\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0883751ae1fc41e283ca853697ee9ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/HUPD/hupd-t5-small/resolve/main/spiece.model in cache at /root/.cache/huggingface/transformers/8c186c2b31d70f51dcbb009506c608856ba67d52cf248e481692af0066844253.d6f0605ae3d57070be74b4c12206072ab332922acff822e6b5458691dbda7551\n",
      "creating metadata file for /root/.cache/huggingface/transformers/8c186c2b31d70f51dcbb009506c608856ba67d52cf248e481692af0066844253.d6f0605ae3d57070be74b4c12206072ab332922acff822e6b5458691dbda7551\n",
      "https://huggingface.co/HUPD/hupd-t5-small/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmphuf9dzv7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f676a4881de4f39ae7a78647663013d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/HUPD/hupd-t5-small/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/35b9f2ae9e8dd32f5084567f7eb551e81bf82d83fce9e35fbdb0fc8de23981b6.d4a380ce1c187f8426a38e50c59e0e53b3ac7b73ec21bc397ca2a8d5343fa14e\n",
      "creating metadata file for /root/.cache/huggingface/transformers/35b9f2ae9e8dd32f5084567f7eb551e81bf82d83fce9e35fbdb0fc8de23981b6.d4a380ce1c187f8426a38e50c59e0e53b3ac7b73ec21bc397ca2a8d5343fa14e\n",
      "https://huggingface.co/HUPD/hupd-t5-small/resolve/main/added_tokens.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp09lctcv6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39f2ac6f6f04d238eaea15e9c095d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/9.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/HUPD/hupd-t5-small/resolve/main/added_tokens.json in cache at /root/.cache/huggingface/transformers/3010ab2bd57d357a31e036c3f0ca65e496ece522b4732b106da784c1025489ff.1f15e307749e285aa0fb98c079fdcabd2d3565639f57352dcc1a6cc878565f83\n",
      "creating metadata file for /root/.cache/huggingface/transformers/3010ab2bd57d357a31e036c3f0ca65e496ece522b4732b106da784c1025489ff.1f15e307749e285aa0fb98c079fdcabd2d3565639f57352dcc1a6cc878565f83\n",
      "https://huggingface.co/HUPD/hupd-t5-small/resolve/main/special_tokens_map.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmprdle5r88\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306268aea7c947088cfd1087446de769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/HUPD/hupd-t5-small/resolve/main/special_tokens_map.json in cache at /root/.cache/huggingface/transformers/589213e0ca907ddf37d53278b5ab2c058b995fd2bf4edc9032352725a61ea0fc.3b392d2ad586f67269821d4f0b0ec75c133778a9abd8c52b92378a4a27f69bd5\n",
      "creating metadata file for /root/.cache/huggingface/transformers/589213e0ca907ddf37d53278b5ab2c058b995fd2bf4edc9032352725a61ea0fc.3b392d2ad586f67269821d4f0b0ec75c133778a9abd8c52b92378a4a27f69bd5\n",
      "loading file https://huggingface.co/HUPD/hupd-t5-small/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/8c186c2b31d70f51dcbb009506c608856ba67d52cf248e481692af0066844253.d6f0605ae3d57070be74b4c12206072ab332922acff822e6b5458691dbda7551\n",
      "loading file https://huggingface.co/HUPD/hupd-t5-small/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/35b9f2ae9e8dd32f5084567f7eb551e81bf82d83fce9e35fbdb0fc8de23981b6.d4a380ce1c187f8426a38e50c59e0e53b3ac7b73ec21bc397ca2a8d5343fa14e\n",
      "loading file https://huggingface.co/HUPD/hupd-t5-small/resolve/main/added_tokens.json from cache at /root/.cache/huggingface/transformers/3010ab2bd57d357a31e036c3f0ca65e496ece522b4732b106da784c1025489ff.1f15e307749e285aa0fb98c079fdcabd2d3565639f57352dcc1a6cc878565f83\n",
      "loading file https://huggingface.co/HUPD/hupd-t5-small/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/589213e0ca907ddf37d53278b5ab2c058b995fd2bf4edc9032352725a61ea0fc.3b392d2ad586f67269821d4f0b0ec75c133778a9abd8c52b92378a4a27f69bd5\n",
      "loading file https://huggingface.co/HUPD/hupd-t5-small/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/4413da3c3cd550e44ab2415f5eb2920e7b6c7f677d703241abcdfa4a5347c481.da4b0a812e9b55b173e4c1a2b57215ddfe312d4ae6e6b1696f4be152dab93bef\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['▁Hello',\n",
       " '▁from',\n",
       " '▁the',\n",
       " '▁greatest',\n",
       " '▁bur',\n",
       " 'ough',\n",
       " '▁in',\n",
       " '▁the',\n",
       " '▁world',\n",
       " '!']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokz = AutoTokenizer.from_pretrained(\"HUPD/hupd-t5-small\")\n",
    "tokz.tokenize(\"Hello from the greatest burough in the world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b01f2e88-69b7-4e86-b9c6-d055f2ef6748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok_func(x): return tokz(x[\"input\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "41b834a5-9a0e-4182-b285-3a50a05fc087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c6f060c2-e3d8-43aa-acf6-87bdba87955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path('./us-patent-phrase-to-phrase-matching')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "843cd082-8617-4b0c-ac41-9f1d3e62dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1230214e-d781-49bb-b791-43ac6ad0f75b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     anchor                  target context  score\n",
       "0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50\n",
       "1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75\n",
       "2  36d72442aefd8232  abatement         active catalyst     A47   0.25\n",
       "3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50\n",
       "4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "26fbd65f-55fc-4099-92a9-24958f13822f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "      <td>36473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36473</td>\n",
       "      <td>733</td>\n",
       "      <td>29340</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>component composite coating</td>\n",
       "      <td>composition</td>\n",
       "      <td>H01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>24</td>\n",
       "      <td>2186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                       anchor       target context\n",
       "count              36473                        36473        36473   36473\n",
       "unique             36473                          733        29340     106\n",
       "top     37d61fd2272659b1  component composite coating  composition     H01\n",
       "freq                   1                          152           24    2186"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "96bb0d4f-5ca0-486d-8d9c-613d8d8b2ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_input(df):\n",
    "    df['input'] = '@CONTEXT: ' + df.context + '; @TARGET: ' + df.target + '; @ANCHOR: ' + df.anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "21055670-466b-45b0-8c6e-b18fc5c6d6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_input(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9680f36d-33eb-4bfd-a873-4fa5aec1d419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0        @CONTEXT: A47; @TARGET: abatement of pollution...\n",
       " 1        @CONTEXT: A47; @TARGET: act of abating; @ANCHO...\n",
       " 2        @CONTEXT: A47; @TARGET: active catalyst; @ANCH...\n",
       " 3        @CONTEXT: A47; @TARGET: eliminating process; @...\n",
       " 4        @CONTEXT: A47; @TARGET: forest region; @ANCHOR...\n",
       "                                ...                        \n",
       " 36468    @CONTEXT: B44; @TARGET: wooden article; @ANCHO...\n",
       " 36469    @CONTEXT: B44; @TARGET: wooden box; @ANCHOR: w...\n",
       " 36470    @CONTEXT: B44; @TARGET: wooden handle; @ANCHOR...\n",
       " 36471    @CONTEXT: B44; @TARGET: wooden material; @ANCH...\n",
       " 36472    @CONTEXT: B44; @TARGET: wooden substrate; @ANC...\n",
       " Name: input, Length: 36473, dtype: object,\n",
       " 0        0.50\n",
       " 1        0.75\n",
       " 2        0.25\n",
       " 3        0.50\n",
       " 4        0.00\n",
       "          ... \n",
       " 36468    1.00\n",
       " 36469    0.50\n",
       " 36470    0.50\n",
       " 36471    0.75\n",
       " 36472    0.50\n",
       " Name: score, Length: 36473, dtype: float64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['input'], df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6c68d69b-7c3d-430d-b96f-ec33095c4d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset,DatasetDict\n",
    "\n",
    "ds = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9dcb08b9-a533-4523-b8ad-520a2dd5f621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'anchor', 'target', 'context', 'score', 'input'],\n",
       "    num_rows: 36473\n",
       "})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "476f08cc-e60a-476b-9af1-5bc463464fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b7714b73034250ba72a265177d63f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tok_ds = ds.map(tok_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f6b631d8-87d1-4e0b-87a4-641b21771c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('@CONTEXT: A47; @TARGET: abatement of pollution; @ANCHOR: abatement',\n",
       " [3320,\n",
       "  17752,\n",
       "  3463,\n",
       "  4,\n",
       "  382,\n",
       "  10,\n",
       "  71,\n",
       "  4177,\n",
       "  117,\n",
       "  3320,\n",
       "  28588,\n",
       "  20750,\n",
       "  10,\n",
       "  703,\n",
       "  9,\n",
       "  14820,\n",
       "  13,\n",
       "  10441,\n",
       "  117,\n",
       "  3320,\n",
       "  23190,\n",
       "  566,\n",
       "  2990,\n",
       "  10,\n",
       "  703,\n",
       "  9,\n",
       "  14820,\n",
       "  1])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = tok_ds[0]\n",
    "row['input'], row['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "afb90414-297f-49bc-9ae4-f652424a6c78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "858"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokz.vocab['of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e6d31f8a-c87b-4b2a-b705-7a07382a97c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 36473\n",
       "})"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_ds = tok_ds.rename_columns({'score':'labels'})\n",
    "tok_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f80a4b4f-ecb1-4243-bc78-42ee2aa51c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>4112d61851461f60</td>\n",
       "      <td>el display</td>\n",
       "      <td>inorganic photoconductor drum</td>\n",
       "      <td>G02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id      anchor                         target context\n",
       "count                 36          36                             36      36\n",
       "unique                36          34                             36      29\n",
       "top     4112d61851461f60  el display  inorganic photoconductor drum     G02\n",
       "freq                   1           2                              1       3"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.read_csv(path/'test.csv')\n",
    "eval_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4e2b3959-a7ab-4efc-838b-c524bc1ac3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5484fa3744841c5b5b822e627ba8916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mk_input(eval_df)\n",
    "eval_ds = Dataset.from_pandas(eval_df).map(tok_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "070bb587-43af-464c-adc7-b8ae0f6ca2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['id', 'anchor', 'target', 'context', 'input', 'input_ids', 'attention_mask'],\n",
       "     num_rows: 36\n",
       " }),\n",
       " ['@CONTEXT: G02; @TARGET: inorganic photoconductor drum; @ANCHOR: opc drum',\n",
       "  '@CONTEXT: F23; @TARGET: altering gas flow; @ANCHOR: adjust gas flow',\n",
       "  '@CONTEXT: B60; @TARGET: lower locating; @ANCHOR: lower trunnion',\n",
       "  '@CONTEXT: D06; @TARGET: upper portion; @ANCHOR: cap component',\n",
       "  '@CONTEXT: H04; @TARGET: artificial neural network; @ANCHOR: neural stimulation',\n",
       "  '@CONTEXT: C12; @TARGET: dry corn starch; @ANCHOR: dry corn',\n",
       "  '@CONTEXT: G11; @TARGET: capacitor housing; @ANCHOR: tunneling capacitor',\n",
       "  '@CONTEXT: B23; @TARGET: contact therapy radiation; @ANCHOR: angular contact bearing',\n",
       "  '@CONTEXT: C10; @TARGET: produce a treated stream; @ANCHOR: produce liquid hydrocarbons',\n",
       "  '@CONTEXT: F02; @TARGET: diesel fuel tanks; @ANCHOR: diesel fuel tank',\n",
       "  '@CONTEXT: B01; @TARGET: dielectric characteristics; @ANCHOR: chemical activity',\n",
       "  '@CONTEXT: H04; @TARGET: direct receiving; @ANCHOR: transmit to platform',\n",
       "  '@CONTEXT: B63; @TARGET: oil carriers; @ANCHOR: oil tankers',\n",
       "  '@CONTEXT: G02; @TARGET: generate by layer; @ANCHOR: generate in layer',\n",
       "  '@CONTEXT: B22; @TARGET: slip portion; @ANCHOR: slip segment',\n",
       "  '@CONTEXT: G02; @TARGET: illumination; @ANCHOR: el display',\n",
       "  '@CONTEXT: E04; @TARGET: oil filler; @ANCHOR: overflow device',\n",
       "  '@CONTEXT: H05; @TARGET: concrete beam; @ANCHOR: beam traveling direction',\n",
       "  '@CONTEXT: C23; @TARGET: electroluminescent; @ANCHOR: el display',\n",
       "  '@CONTEXT: H02; @TARGET: power detection; @ANCHOR: equipment unit',\n",
       "  '@CONTEXT: C07; @TARGET: halogen addition reaction; @ANCHOR: halocarbyl',\n",
       "  '@CONTEXT: A63; @TARGET: hydroxy; @ANCHOR: perfluoroalkyl group',\n",
       "  '@CONTEXT: G05; @TARGET: control loop; @ANCHOR: speed control means',\n",
       "  '@CONTEXT: F16; @TARGET: steel plate; @ANCHOR: arm design',\n",
       "  '@CONTEXT: F04; @TARGET: bearing system; @ANCHOR: hybrid bearing',\n",
       "  '@CONTEXT: A44; @TARGET: end days; @ANCHOR: end pins',\n",
       "  '@CONTEXT: B61; @TARGET: organic farming; @ANCHOR: organic starting',\n",
       "  '@CONTEXT: E04; @TARGET: making cake; @ANCHOR: make of slabs',\n",
       "  '@CONTEXT: F01; @TARGET: teeth whitening; @ANCHOR: seal teeth',\n",
       "  '@CONTEXT: B60; @TARGET: carry on platform; @ANCHOR: carry by platform',\n",
       "  '@CONTEXT: B21; @TARGET: pooling device; @ANCHOR: polls',\n",
       "  '@CONTEXT: A61; @TARGET: end visual; @ANCHOR: upper clamp arm',\n",
       "  '@CONTEXT: G01; @TARGET: clocked storage device; @ANCHOR: clocked storage',\n",
       "  '@CONTEXT: G01; @TARGET: turns impedance; @ANCHOR: coupling factor',\n",
       "  '@CONTEXT: H03; @TARGET: carrier polarity; @ANCHOR: different conductivity',\n",
       "  '@CONTEXT: F16; @TARGET: corrosion resistant; @ANCHOR: hybrid bearing'])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ds, eval_ds['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4cf73302-897f-4e1a-9660-457e947aa31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 27354\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'anchor', 'target', 'context', 'labels', 'input', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 9119\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dds = tok_ds.train_test_split(0.25, seed=42)\n",
    "dds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "777c1700-2967-4a7d-835c-b94ee7dfdb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -Uqq evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8be92c3f-c261-4bfb-9333-92cbe32d6a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "# def corr(x,y): return np.corrcoef(x,y)[0][1]\n",
    "# def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}\n",
    "def corr(x, y):\n",
    "    metric = evaluate.load('pearsonr')\n",
    "    return metric.compute(predictions=x, references=y)['pearsonr']\n",
    "def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}\n",
    "\n",
    "# def corr_d(eval_preds):\n",
    "#     metric = evaluate.load(\"pearsonr\")\n",
    "#     logits, labels = eval_preds\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e470aa7d-7f49-4f9e-bbb5-c2475a4247a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.9/dist-packages (0.0.post11)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37317278-1b4f-4fd6-9cf3-a7699ee69e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7506</th>\n",
       "      <td>3.0550</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.152778</td>\n",
       "      <td>1.048611</td>\n",
       "      <td>729.0</td>\n",
       "      <td>5.062500</td>\n",
       "      <td>33.92</td>\n",
       "      <td>-118.28</td>\n",
       "      <td>1.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>3.0862</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.697897</td>\n",
       "      <td>1.055449</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>2.216061</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.37</td>\n",
       "      <td>3.453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12888</th>\n",
       "      <td>2.5556</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.864905</td>\n",
       "      <td>1.129222</td>\n",
       "      <td>1631.0</td>\n",
       "      <td>2.395007</td>\n",
       "      <td>38.66</td>\n",
       "      <td>-121.35</td>\n",
       "      <td>1.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13344</th>\n",
       "      <td>3.0057</td>\n",
       "      <td>32.0</td>\n",
       "      <td>4.212687</td>\n",
       "      <td>0.936567</td>\n",
       "      <td>1378.0</td>\n",
       "      <td>5.141791</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-117.64</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7173</th>\n",
       "      <td>1.9083</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.888554</td>\n",
       "      <td>1.039157</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>4.623494</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.19</td>\n",
       "      <td>1.192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "7506   3.0550      37.0  5.152778   1.048611       729.0  5.062500     33.92   \n",
       "4720   3.0862      35.0  4.697897   1.055449      1159.0  2.216061     34.05   \n",
       "12888  2.5556      24.0  4.864905   1.129222      1631.0  2.395007     38.66   \n",
       "13344  3.0057      32.0  4.212687   0.936567      1378.0  5.141791     34.05   \n",
       "7173   1.9083      42.0  3.888554   1.039157      1535.0  4.623494     34.05   \n",
       "\n",
       "       Longitude  MedHouseVal  \n",
       "7506     -118.28        1.054  \n",
       "4720     -118.37        3.453  \n",
       "12888    -121.35        1.057  \n",
       "13344    -117.64        0.969  \n",
       "7173     -118.19        1.192  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "housing = housing['data'].join(housing['target']).sample(1000, random_state=52)\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a6be51ac-b380-4240-877d-a08c50946976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_corr(df, a, b):\n",
    "    x,y = df[a].values,df[b].values\n",
    "    plt.scatter(x,y, alpha=0.5, s=4)\n",
    "    plt.title(f'{a} vs {b}; r: {corr(x, y):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60686daf-8818-4306-ba10-15dd100d4150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3.0550, dtype=torch.float64),\n",
       " 7506     1.054\n",
       " 4720     3.453\n",
       " 12888    1.057\n",
       " 13344    0.969\n",
       " 7173     1.192\n",
       "          ...  \n",
       " 10535    2.454\n",
       " 3029     0.638\n",
       " 7985     1.563\n",
       " 13724    0.728\n",
       " 13520    2.213\n",
       " Name: MedHouseVal, Length: 1000, dtype: float64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(housing.MedInc.values)[0], housing.MedHouseVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50f9e95f-f276-4690-b3c2-f3ab71396a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(housing.MedInc.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "232e362d-549e-4656-a450-4dd4426e97de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_corr(housing, 'MedInc', 'MedHouseVal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "28f8b067-98b6-4ecd-b57b-7eb45a721ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments,Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5f340b63-8ee4-47d9-927f-c86b24efd286",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "epochs = 8\n",
    "lr = 8e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e9d42bfd-7193-40bb-ba11-13e3d4753d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n",
    "    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n",
    "    num_train_epochs=epochs, weight_decay=0.01, report_to='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "51f10eb0-a335-4f93-8ef0-b1a54bd64e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8f98f6d0-57df-42cb-8980-465dccea2dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer, AutoConfig, AutoModelForSeq2SeqLM\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A custom model class that wraps the pretrained model and adds a classification head\n",
    "class T5ForSequenceClassification(nn.Module):\n",
    "    def __init__(self, model_name, num_labels=1):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name, return_dict=True)\n",
    "        self.dropout = nn.Dropout(0.05)\n",
    "        self.classifier = nn.Linear(self.model.config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, labels=None):\n",
    "        outputs = self.model(input_ids, attention_mask=attention_mask, decoder_input_ids=decoder_input_ids, decoder_attention_mask=decoder_attention_mask, labels=labels)\n",
    "        logits = outputs.logits\n",
    "        logits = self.dropout(logits)\n",
    "        logits = self.classifier(logits)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4d099740-072c-4c7f-806a-759dcc7b9cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/HUPD/hupd-t5-small/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/9425558ac734557ed56c155eb3bef940ddd174dc94466e0d9a5574e0d24f3c63.151a855e73e71b86bc38b653969dd0b3939b953f16cc8f1fcbba115f9439f6a7\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"HUPD/hupd-t5-small\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"relu\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"relu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": false,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 6,\n",
      "  \"num_heads\": 8,\n",
      "  \"num_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32739\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/HUPD/hupd-t5-small/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/1c31add4a5f2c4d46c78097faa5514cb9c947e75afa8c19ce4aaf6fe426267b3.99cd7df01fefaa72ab7b89bebdaf2138f13a56dc2015a49e51420e40ca593941\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at HUPD/hupd-t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like T5ForConditionalGeneration(\n  (shared): Embedding(32739, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32739, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (2): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (3): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (4): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (5): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32739, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (2): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (3): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (4): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (5): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32739, bias=False)\n) is not the path to a directory containing a config.json file.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/configuration_utils.py:601\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    600\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 601\u001b[0m     resolved_config_file \u001b[39m=\u001b[39m cached_path(\n\u001b[1;32m    602\u001b[0m         config_file,\n\u001b[1;32m    603\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    604\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    605\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    606\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    607\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    608\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    609\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    610\u001b[0m     )\n\u001b[1;32m    612\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/utils/hub.py:284\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    283\u001b[0m     \u001b[39m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     output_path \u001b[39m=\u001b[39m get_from_cache(\n\u001b[1;32m    285\u001b[0m         url_or_filename,\n\u001b[1;32m    286\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    287\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    288\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    289\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    290\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    291\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    292\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    293\u001b[0m     )\n\u001b[1;32m    294\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    295\u001b[0m     \u001b[39m# File, and it exists.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/utils/hub.py:554\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 554\u001b[0m                 \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    555\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mConnection error, and we cannot find the requested files in the cached path.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    556\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m Please try again or make sure your Internet connection is on.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    557\u001b[0m                 )\n\u001b[1;32m    559\u001b[0m \u001b[39m# From now on, etag is not None.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/home/zmack/workspace/deep-thoughts/posts/lesson 4/try2-hupd-tf.ipynb Cell 38\u001b[0m line \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/zmack/workspace/deep-thoughts/posts/lesson%204/try2-hupd-tf.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model_nm \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mHUPD/hupd-t5-small\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/zmack/workspace/deep-thoughts/posts/lesson%204/try2-hupd-tf.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m AutoModelForSeq2SeqLM\u001b[39m.\u001b[39mfrom_pretrained(model_nm)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/zmack/workspace/deep-thoughts/posts/lesson%204/try2-hupd-tf.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m custom_model \u001b[39m=\u001b[39m T5ForSequenceClassification(model, \u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32m/home/zmack/workspace/deep-thoughts/posts/lesson 4/try2-hupd-tf.ipynb Cell 38\u001b[0m line \u001b[0;36mT5ForSequenceClassification.__init__\u001b[0;34m(self, model_name, num_labels)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/zmack/workspace/deep-thoughts/posts/lesson%204/try2-hupd-tf.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/zmack/workspace/deep-thoughts/posts/lesson%204/try2-hupd-tf.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_labels \u001b[39m=\u001b[39m num_labels\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/zmack/workspace/deep-thoughts/posts/lesson%204/try2-hupd-tf.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m AutoModelForSeq2SeqLM\u001b[39m.\u001b[39;49mfrom_pretrained(model_name, return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/zmack/workspace/deep-thoughts/posts/lesson%204/try2-hupd-tf.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mDropout(\u001b[39m0.05\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/zmack/workspace/deep-thoughts/posts/lesson%204/try2-hupd-tf.ipynb#X52sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mhidden_size, num_labels)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/auto/auto_factory.py:423\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39m_from_auto\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m--> 423\u001b[0m     config, kwargs \u001b[39m=\u001b[39m AutoConfig\u001b[39m.\u001b[39;49mfrom_pretrained(\n\u001b[1;32m    424\u001b[0m         pretrained_model_name_or_path, return_unused_kwargs\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, trust_remote_code\u001b[39m=\u001b[39;49mtrust_remote_code, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    425\u001b[0m     )\n\u001b[1;32m    426\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(config, \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mauto_map:\n\u001b[1;32m    427\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/models/auto/configuration_auto.py:705\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    703\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mname_or_path\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m pretrained_model_name_or_path\n\u001b[1;32m    704\u001b[0m trust_remote_code \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mtrust_remote_code\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 705\u001b[0m config_dict, _ \u001b[39m=\u001b[39m PretrainedConfig\u001b[39m.\u001b[39;49mget_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    706\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mAutoConfig\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict[\u001b[39m\"\u001b[39m\u001b[39mauto_map\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    707\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/configuration_utils.py:553\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m original_kwargs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    552\u001b[0m \u001b[39m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m config_dict, kwargs \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_config_dict(pretrained_model_name_or_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    555\u001b[0m \u001b[39m# That config file may point us toward another config file to use.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mconfiguration_files\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config_dict:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/configuration_utils.py:634\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    631\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThere was a specific connection error when trying to load \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00merr\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    632\u001b[0m     )\n\u001b[1;32m    633\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m--> 634\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    635\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mWe couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt connect to \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to load this model, couldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find it in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    636\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m the cached files and it looks like \u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m is not the path to a directory\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    637\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m containing a \u001b[39m\u001b[39m{\u001b[39;00mconfiguration_file\u001b[39m}\u001b[39;00m\u001b[39m file.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCheckout your internet connection or see how to run the\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    638\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m library in offline mode at \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    639\u001b[0m     )\n\u001b[1;32m    640\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    642\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt load config for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. If you were trying to load it from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    643\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, make sure you don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt have a local directory with the same name. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    644\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOtherwise, make sure \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpretrained_model_name_or_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m is the correct path to a directory \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    645\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcontaining a \u001b[39m\u001b[39m{\u001b[39;00mconfiguration_file\u001b[39m}\u001b[39;00m\u001b[39m file\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    646\u001b[0m     )\n",
      "\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like T5ForConditionalGeneration(\n  (shared): Embedding(32739, 512)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32739, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (2): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (3): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (4): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (5): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32739, 512)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n              (relative_attention_bias): Embedding(32, 8)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (2): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (3): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (4): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (5): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=512, out_features=512, bias=False)\n              (k): Linear(in_features=512, out_features=512, bias=False)\n              (v): Linear(in_features=512, out_features=512, bias=False)\n              (o): Linear(in_features=512, out_features=512, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=512, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=512, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=512, out_features=32739, bias=False)\n) is not the path to a directory containing a config.json file.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "model_nm = \"HUPD/hupd-t5-small\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_nm)\n",
    "custom_model = T5ForSequenceClassification(model, 1)\n",
    "# custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183bf037-d6f7-440d-90ff-a390cdf791ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(custom_model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n",
    "                  tokenizer=tokz, compute_metrics=corr_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0c00b3d3-f398-4c4d-bbaf-94c1b585ff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `CustomClassifier.forward` and have been ignored: labels, context, id, anchor, target, input. If labels, context, id, anchor, target, input are not expected by `CustomClassifier.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 27354\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([128, 33])\n",
      "Attention Mask shape: torch.Size([128, 33])\n",
      "Last hidden state shape: torch.Size([128, 33, 512])\n",
      "Pooled output shape: torch.Size([128, 512])\n",
      "Shape of logits: torch.Size([128, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [] doesn't match the broadcast shape [1]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/zmack/workspace/deep-thoughts/posts/lesson 4/try2-hupd-tf.ipynb Cell 40\u001b[0m line \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/zmack/workspace/deep-thoughts/posts/lesson%204/try2-hupd-tf.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py:1409\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1406\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1407\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1408\u001b[0m )\n\u001b[0;32m-> 1409\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1410\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1411\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1412\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1413\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1414\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py:1661\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1660\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1661\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss_step\n\u001b[1;32m   1663\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_flos \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfloating_point_ops(inputs))\n\u001b[1;32m   1665\u001b[0m \u001b[39m# Optimizer step for deepspeed must be called on every step regardless of the value of gradient_accumulation_steps\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output with shape [] doesn't match the broadcast shape [1]"
     ]
    }
   ],
   "source": [
    "trainer.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "53026251-472b-4831-85d8-5463c7f15f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set don't have a corresponding argument in `CustomClassifier.forward` and have been ignored: context, id, anchor, target, input. If context, id, anchor, target, input are not expected by `CustomClassifier.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 36\n",
      "  Batch size = 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs shape: torch.Size([36, 33])\n",
      "Attention Mask shape: torch.Size([36, 33])\n",
      "Last hidden state shape: torch.Size([36, 33, 512])\n",
      "Pooled output shape: torch.Size([36, 512])\n",
      "Shape of logits: torch.Size([36, 1])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NotebookTrainingTracker' object has no attribute 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [170]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_ds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpredictions\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py:2695\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2692\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   2694\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 2695\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[1;32m   2697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2698\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   2699\u001b[0m output\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m   2700\u001b[0m     speed_metrics(\n\u001b[1;32m   2701\u001b[0m         metric_key_prefix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2705\u001b[0m     )\n\u001b[1;32m   2706\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer.py:2826\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2824\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics(logits, labels)\n\u001b[1;32m   2825\u001b[0m     preds_host \u001b[38;5;241m=\u001b[39m logits \u001b[38;5;28;01mif\u001b[39;00m preds_host \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m nested_concat(preds_host, logits, padding_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m-> 2826\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_prediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2828\u001b[0m \u001b[38;5;66;03m# Gather all tensors and put them back on the CPU if we have done enough accumulation steps.\u001b[39;00m\n\u001b[1;32m   2829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39meval_accumulation_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m args\u001b[38;5;241m.\u001b[39meval_accumulation_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer_callback.py:384\u001b[0m, in \u001b[0;36mCallbackHandler.on_prediction_step\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_prediction_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[0;32m--> 384\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_event\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_prediction_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/trainer_callback.py:388\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, event, args, state, control, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 388\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/utils/notebook.py:308\u001b[0m, in \u001b[0;36mNotebookProgressCallback.on_prediction_step\u001b[0;34m(self, args, state, control, eval_dataloader, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_bar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_bar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/utils/notebook.py:162\u001b[0m, in \u001b[0;36mNotebookProgressBar.update\u001b[0;34m(self, value, force_update, comment)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_time_per_item \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicted_remaining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_time_per_item \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m-\u001b[39m value)\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_bar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_value \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_time \u001b[38;5;241m=\u001b[39m current_time\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/utils/notebook.py:183\u001b[0m, in \u001b[0;36mNotebookProgressBar.update_bar\u001b[0;34m(self, value, comment)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_time_per_item\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m it/s\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomment) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/utils/notebook.py:189\u001b[0m, in \u001b[0;36mNotebookProgressBar.display\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhtml_code \u001b[38;5;241m=\u001b[39m html_progress_bar(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;66;03m# If this is a child bar, the parent will take care of the display.\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/transformers/utils/notebook.py:219\u001b[0m, in \u001b[0;36mNotebookTrainingTracker.display\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdisplay\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhtml_code \u001b[38;5;241m=\u001b[39m html_progress_bar(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefix, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth)\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minner_table \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhtml_code \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m text_to_html_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minner_table)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NotebookTrainingTracker' object has no attribute 'value'"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(eval_ds).predictions.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "eb7ac7c4-7e0a-425f-8325-e9e404c4b4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.51806641e-01],\n",
       "       [ 5.28320312e-01],\n",
       "       [ 4.32128906e-01],\n",
       "       [ 1.93969727e-01],\n",
       "       [-3.70407104e-03],\n",
       "       [ 5.15136719e-01],\n",
       "       [ 5.05371094e-01],\n",
       "       [ 3.23104858e-03],\n",
       "       [ 2.74902344e-01],\n",
       "       [ 1.09277344e+00],\n",
       "       [ 2.02758789e-01],\n",
       "       [ 2.81982422e-01],\n",
       "       [ 6.48437500e-01],\n",
       "       [ 8.80371094e-01],\n",
       "       [ 8.46191406e-01],\n",
       "       [ 3.86230469e-01],\n",
       "       [ 2.34619141e-01],\n",
       "       [-3.44276428e-04],\n",
       "       [ 5.82031250e-01],\n",
       "       [ 4.28466797e-01],\n",
       "       [ 4.51660156e-01],\n",
       "       [ 2.26196289e-01],\n",
       "       [ 2.62207031e-01],\n",
       "       [ 2.50000000e-01],\n",
       "       [ 4.86083984e-01],\n",
       "       [ 7.81250000e-03],\n",
       "       [-8.13293457e-03],\n",
       "       [ 9.07897949e-03],\n",
       "       [ 5.00869751e-03],\n",
       "       [ 6.51855469e-01],\n",
       "       [ 2.73681641e-01],\n",
       "       [ 1.74427032e-03],\n",
       "       [ 7.96386719e-01],\n",
       "       [ 5.12207031e-01],\n",
       "       [ 2.64892578e-01],\n",
       "       [ 2.57080078e-01]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b9ebd00b-a1bd-42f9-bce6-300a329ad62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.clip(preds, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3d7706e8-f3f2-478b-8d49-3e17c49eeee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35180664],\n",
       "       [0.52832031],\n",
       "       [0.43212891],\n",
       "       [0.19396973],\n",
       "       [0.        ],\n",
       "       [0.51513672],\n",
       "       [0.50537109],\n",
       "       [0.00323105],\n",
       "       [0.27490234],\n",
       "       [1.        ],\n",
       "       [0.20275879],\n",
       "       [0.28198242],\n",
       "       [0.6484375 ],\n",
       "       [0.88037109],\n",
       "       [0.84619141],\n",
       "       [0.38623047],\n",
       "       [0.23461914],\n",
       "       [0.        ],\n",
       "       [0.58203125],\n",
       "       [0.4284668 ],\n",
       "       [0.45166016],\n",
       "       [0.22619629],\n",
       "       [0.26220703],\n",
       "       [0.25      ],\n",
       "       [0.48608398],\n",
       "       [0.0078125 ],\n",
       "       [0.        ],\n",
       "       [0.00907898],\n",
       "       [0.0050087 ],\n",
       "       [0.65185547],\n",
       "       [0.27368164],\n",
       "       [0.00174427],\n",
       "       [0.79638672],\n",
       "       [0.51220703],\n",
       "       [0.26489258],\n",
       "       [0.25708008]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36393444-847d-4dcb-a1a9-b60b16322f25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
